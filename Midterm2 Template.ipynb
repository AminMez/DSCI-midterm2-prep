{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e18f9f-99b3-4d27-8e83-02b0eec64f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification template \n",
    "\n",
    "set.seed(....)\n",
    "df <- read_csv(\"...\")\n",
    "df_split <- initial_split(df,prop=...,strata = ...)\n",
    "df_training <- training(df_split)\n",
    "df_testing <- testing(df_split)\n",
    "\n",
    "##testing the number of neighbors \n",
    "knn_spec_tune <- nearest_neighbor(weight_func = \"rectangular\",neighbors = tune())|>\n",
    "  set_engine(\"kknn\")|>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "##recipe of data \n",
    "df_recipe <- recipe(...~... ,data=df_training)|>\n",
    "  step_center(all_predictors())|>\n",
    "  step_scale(all_predictors())\n",
    "\n",
    "##cross-validation fold\n",
    "df_vfold <- vfold_cv(df_training, v = ..., strata = ...)\n",
    "\n",
    "gridvals = tibble(neighbors = seq(from=...,to=..., by=...))\n",
    "\n",
    "## collect the accuracies of different neighbour and give mean accuracy from validation sets\n",
    "knn_tune_result <- workflow()|>\n",
    "  add_recipe(df_recipe)|>\n",
    "  add_model(df_model)|>\n",
    "  tune_grid(resamples = df_vfold, grid = gridvals)|>\n",
    "  collect_metrics()|>\n",
    "  filter(.metric==\"accuracy\")|>\n",
    "  arrange(desc(mean))\n",
    "\n",
    "##pull the best number of neighbors\n",
    "best_k <- knn_tune_result|>\n",
    "    slice(1)|>\n",
    "    pull(neighbor)\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\",neighbors = best_k)|>\n",
    "  set_engine(\"kknn\")|>\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "##fit the prediction model\n",
    "df_fit <- workflow()|>\n",
    "  add_recipe(df_recipe)|>\n",
    "  add_model(knn_spec)|>\n",
    "  fit(data=df_training)\n",
    "\n",
    "##predict the test set \n",
    "result <- df_fit|>\n",
    "  predict(df_testing)|>\n",
    "  bind_cols(df_testing)\n",
    "\n",
    "result_metrics <- result|>\n",
    "    metrics(truth=...,estimate = .pred_class)|>\n",
    "    filter(.metric=\"accuracy\")\n",
    "\n",
    "result_confusion <- result|>\n",
    "    conf_mat(truth=...,estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f66310-d46e-4c5e-97b5-8a60c2cae5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##prediction template \n",
    "\n",
    "# set.seed(....)\n",
    "# df <- read_csv(\"...\")\n",
    "# df_split <- initial_split(df,prop=...,strata = ...)\n",
    "# df_training <- training(df_split)\n",
    "# df_testing <- testing(df_split)\n",
    "\n",
    "# ##testing the number of neighbors \n",
    "# knn_tune <- nearest_neighbor(weight_func = \"rectangular\",neighbors = tune())|>\n",
    "#   set_engine(\"kknn\")|>\n",
    "#   set_mode(\"regression\")\n",
    "\n",
    "# ##recipe of data \n",
    "# df_recipe <- recipe(...~... ,data=df_training)\n",
    "\n",
    "# ##cross-validation fold\n",
    "# df_vfold <- vfold_cv(df_training, v = ..., strata = ...)\n",
    "\n",
    "# gridvals = tibble(neighbors = seq(from=...,to=..., by=...))\n",
    "\n",
    "\n",
    "# ##produce the metrics of cross validation sets with different number of neighbours\n",
    "# tune_result <- workflow()|>\n",
    "#   add_model(knn_tune)|>\n",
    "#   add_recipe(df_recipe)|>\n",
    "#   tune_grid(resamples=df_vfold,grid=gridvals)|>\n",
    "#   collect_metrics()\n",
    "\n",
    "# ##produce the rmse of cross validation sets\n",
    "# tune_rmse <- tune_result|>\n",
    "#     filter(.metric==\"rmse\")\n",
    "\n",
    "# ##pick the number of neighbors that has the minimal rmse\n",
    "# best_k <- tune_rmse|>\n",
    "#   arrange(mean)|>\n",
    "#   slice(1)|>\n",
    "#   pull(neighbors)\n",
    "\n",
    "# knn_spec <- nearest_neighbor(weight_func=\"rectangular\",neighbors = best_k)|>\n",
    "#   set_engine(\"kknn\")|>\n",
    "#   set_mode(\"regression\")\n",
    "\n",
    "# best_fit <- workflow()|>\n",
    "#   add_recipe(df_recipe)|>\n",
    "#   add_model(knn_spec)|>\n",
    "#   fit(data=df_training)\n",
    "\n",
    "# prediction_result <- best_fit|>\n",
    "#   predict(df_testing)|>\n",
    "#   bind_cols(df_testing)\n",
    "\n",
    "# ##produce the rms\n",
    "# prediction_rmspe <- prediction_result|>\n",
    "#   metrics(truth=... ,estimate=.pred)|>\n",
    "#   filter(.metric==\"rmse\")\n",
    "#   pull(.estimate)\n",
    "\n",
    "# training_rmse <- best_fit |>\n",
    "#   predict(df_training) |>\n",
    "#   bind_cols(df_training)|>\n",
    "#   metrics(truth=... ,estimate=.pred)|>\n",
    "#   filter(.metric==\"rmse\")\n",
    "#   pull(.estimate)\n",
    "\n",
    "# ##regression plot \n",
    "\n",
    "# training_pred -> best_fit|>\n",
    "#     predict(df_training)|>\n",
    "#     bind_cols(df_training)\n",
    "\n",
    "# prediction_plot <- training_pred|>\n",
    "#   ggplot(aes(x=...,y=...))+\n",
    "#   geom_point()+\n",
    "#   geom_line(data=training_preds,aes(x=...,y=.pred),col=\"blue\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
